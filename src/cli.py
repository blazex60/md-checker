from __future__ import annotations

import argparse
import os
import json
from pathlib import Path

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å†…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# å®Ÿè¡Œæ™‚ã¯ 'mdcheck' ã‚³ãƒãƒ³ãƒ‰ã€ã¾ãŸã¯ 'python -m src.mdcheck.cli' ãªã©ã§å‘¼ã³å‡ºã—ã¾ã™
from ollama_client import pull_model, lint_with_llm
from rules import lint_with_rules  # <--- è¿½åŠ 

def print_analysis(advice: dict, source: str = "LLM") -> None:
    """è§£æçµæœã‚’è¡¨ç¤ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    
    # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    title = f" ğŸ” Analysis Report ({source}) "
    print("\n" + title.center(60, "="))

    # --- Rule Based Issues (ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®çµæœç”¨) ---
    rule_issues = advice.get("rule_based_issues", [])
    if rule_issues:
        print("\n[Basic Formatting Issues]")
        for issue in rule_issues:
            print(f" â€¢ {issue}")
    elif source == "Rules":
        print("\n[Basic Formatting Issues]\n (No issues found)")

    # --- LLM Based Results (LLMã®çµæœç”¨) ---
    
    # Terms
    terms = advice.get("terms", [])
    if terms:
        print("\n[Terms / Proper Nouns]")
        for t in terms:
            surface = t.get("surface", "???")
            note = t.get("note", "")
            print(f" â€¢ {surface:<20} | {note}")

    # Inconsistencies
    inconsistencies = advice.get("inconsistencies", [])
    if inconsistencies:
        print("\n[Inconsistencies]")
        for i in inconsistencies:
            a = i.get("a", "?")
            b = i.get("b", "?")
            note = i.get("note", "")
            itype = i.get("type", "style")
            print(f" â€¢ {a} <-> {b} ({itype})\n   â””â”€ {note}")

    # Suggestions
    suggestions = advice.get("suggestions", [])
    if suggestions:
        print("\n[AI Suggestions]")
        for s in suggestions:
            print(f" â€¢ {s}")

    print("\n" + "="*60 + "\n")


def process_file(file_path: Path, use_llm: bool) -> None:
    """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
    print(f"Checking: {file_path}")
    
    try:
        text = file_path.read_text(encoding="utf-8")
    except Exception as e:
        print(f"Error reading file: {e}")
        return

    # ã€å¤‰æ›´ç‚¹ã€‘
    # 1. ã¾ãšãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œï¼ˆå¸¸ã«å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
    rule_result = lint_with_rules(text)
    print_analysis(rule_result, source="Rules")

    # 2. --llm ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆã®ã¿ã€è¿½åŠ ã§LLMãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    if use_llm:
        print("Waiting for LLM response...")
        try:
            # å…¥åŠ›ä¸Šé™ã¯ä¸€æ—¦1500æ–‡å­—
            advice = lint_with_llm(text[:1500])
            print_analysis(advice, source="AI (Ollama)")
        except Exception as e:
            print(f"LLM Error: {e}")
            print("(Ensure Ollama is running and model is pulled)")
    else:
        # LLMãŒç„¡åŠ¹ãªå ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆæ”¹è¡Œèª¿æ•´æ¸ˆã¿ï¼‰
        print("  -> AI check is skipped. Use --llm to enable.")
        print()


def main(argv: list[str] | None = None) -> None:
    p = argparse.ArgumentParser(prog="mdcheck")
    p.add_argument("path", nargs="?", help="Markdown file or directory path")
    p.add_argument("--llm", action="store_true", help="Enable LLM advice via Ollama")
    p.add_argument("--pull-model", action="store_true", help="Pull Ollama model and exit")
    args = p.parse_args(argv)

    if args.pull_model:
        pull_model()
        print(f"[OK] pulled model: {os.getenv('OLLAMA_MODEL', 'gemma2:2b')}")
        return

    if not args.path:
        p.print_help()
        raise SystemExit(1)

    target_path = Path(args.path)

    if not target_path.exists():
        raise SystemExit(f"Path not found: {target_path}")

    if target_path.is_dir():
        md_files = list(target_path.glob("*.md"))
        if not md_files:
            print(f"No markdown files found in {target_path}")
            return
            
        print(f"Found {len(md_files)} markdown files in {target_path}\n")
        for md_file in md_files:
            process_file(md_file, args.llm)
            
    elif target_path.is_file():
        process_file(target_path, args.llm)
        
    else:
        print(f"Error: {target_path} is not a valid file or directory")


if __name__ == "__main__":
    main()